data:
  batch_size: 32
  dataset:
    name: ALOSDataset
    trainpath: ../../datasets/SAN_FRANCISCO_ALOS2
  #transform: LogAmplitude, Amplitude
  #transform: LogAmplitude, RealImaginary
  transform: LogAmplitude
  img_size: 64
  img_stride: 64
  num_workers: 4
  valid_ratio: 0.15
  test_ratio: 0.15
  crop:
    end_col: 3200
    end_row: 7500
    start_col: 1000
    start_row: 3000
logging:
  logdir: ./logs
  wandb:
    entity: equivariant_cvnn
    project: sf_alos2
loss:
  name: ComplexMSELoss
model:
  #activation: ReLU
  activation: modReLU
  channels_ratio: 16
  class: AutoEncoderWD
  res: true
  projection:
    class: ModCtoR
    #class: NoCtoR
    #class: PolyCtModCtoRoR
    #class: MLPCtoR
    #global: false
    global: true
  #downsampling: MaxPool
  downsampling: StridedConv
  #downsampling: AvgPool
  #downsampling: LPD
  #downsampling: APS
  #downsampling: LPF
  upsampling: Upsample
  #upsampling: Null
  #upsampling: ConvTranspose
  #upsampling: LPU
  latent_dim: Null
  dropout : 0
  normalization: 
    method: BatchNorm
    #method: Null
    #method: LayerNorm
    track_running_stats: false
  num_layers: 4
  gumbel_tau:
    start_value: 10
    gamma: 0.1
    start_decay_epoch: 10
    min_value: 0.00001
nepochs: 300
optim:
  algo: AdamW
  params:
    lr: 0.001
    weight_decay: 0
scheduler:
  algo: StepLR
  params:
    step_size: 10000
    gamma: 0.9
  # algo: ReduceLROnPlateau
  # params:
  #   mode: min
  #   factor: 0.5
  #   patience: 5
  #   min_lr: 0.0005
  # algo: CyclicLR
  # params:
  #   base_lr: 0.0001
  #   max_lr: 0.001
  #   step_size_up: 100
  #   mode: triangular
  # algo: OneCycleLR
  # params:
  #   max_lr: 0.001
  # algo: CosineAnnealingLR
  # params:
  #   eta_min: 0.00005
  #algo: CosineAnnealingWarmRestarts
  #params:
    #T_0: 10
    #T_mult: 1
    #eta_min: 0.0001
pretrained: false
world_size: 4
dtype: complex64
#dtype: float64