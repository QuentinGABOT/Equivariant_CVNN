data:
  batch_size: 128
  dataset:
    name: PolSFDataset
    trainpath: ../datasets/SAN_FRANCISCO_ALOS2
  #transform: LogAmplitude, Amplitude
  #transform: LogAmplitude, RealImaginary
  transform: LogAmplitude
  img_size: 16
  img_stride: 16
  num_workers: 4
  valid_ratio: 0.2
  test_ratio: 0.2
logging:
  logdir: ./logs
  wandb:
    entity: equivariant_cvnn
    project: polsf
loss:
  name: FocalLoss
  gamma: 5
model:
  #activation: ReLU
  activation: modReLU
  channels_ratio: 16
  class: UNet
  res: true
  projection:
    #class: ModCtoR
    class: NoCtoR
    #class: PolyCtoR
    #class: MLPCtoR
    #global: false
    global: true
    #softmax: SoftmaxMeanCtoR
    softmax: SoftmaxProductCtoR
    #softmax: Softmax
  #downsampling: MaxPool
  #downsampling: Null
  downsampling: AvgPool
  #downsampling: LPD
  #downsampling: APS
  #downsampling: LPF
  #upsampling: Upsample
  #upsampling: Null
  upsampling: ConvTranspose
  #upsampling: LPU
  latent_dim: 8192
  dropout : 0.1
  normalization: 
    method: BatchNorm
    #method: Null
    #method: LayerNorm
    track_running_stats: false
  num_layers: 4
  gumbel_tau:
    start_value: 10
    gamma: 0.1
    start_decay_epoch: 10
    min_value: 0.00001
nepochs: 100
optim:
  algo: AdamW
  params:
    lr: 0.005
    weight_decay: 0.005
scheduler:
  #algo: StepLR
  #params:
    #step_size: 5
    #gamma: 0.9
  # algo: ReduceLROnPlateau
  # params:
  #   mode: min
  #   factor: 0.5
  #   patience: 5
  #   min_lr: 0.0005
  # algo: CyclicLR
  # params:
  #   base_lr: 0.0001
  #   max_lr: 0.001
  #   step_size_up: 100
  #   mode: triangular
  algo: OneCycleLR
  params:
    max_lr: 0.001
  #algo: CosineAnnealingLR
  #params:
    #eta_min: 0.00005
  #algo: CosineAnnealingWarmRestarts
  #params:
    #T_0: 10
    #T_mult: 1
    #eta_min: 0.0001
pretrained: false
world_size: 4
dtype: complex64
#dtype: float64